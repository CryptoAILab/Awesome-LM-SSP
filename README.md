<img src="figure/title.png" alt="image" width="1000" height="auto" class="center">

<img src="https://badges.toozhao.com/badges/01HMRJE3211AJ2QD2X9AKTQG67/blue.svg"> <img alt="Stars" src="https://img.shields.io/github/stars/ThuCCSLab/lm-ssp">

# Introduction 

The resources related to the trustworthiness of large models (LMs) across multiple dimensions (e.g., safety, security, and privacy),                  with a special focus on multi-modal LMs (e.g., vision-language models and diffusion models). 

- This repo is in progress :seedling: (currently manually collected).
- Badges: 

    - Model: ![img](https://img.shields.io/badge/llm-589cf4) ![img](https://img.shields.io/badge/vlm-c7688b)  ![img](https://img.shields.io/badge/diffusion-a99cf4) 

    - Comment: ![img](https://img.shields.io/badge/Benchmark-87b800) ![img](https://img.shields.io/badge/New_dataset-87b800) ![img](https://img.shields.io/badge/Agent-87b800)                 ![img](https://img.shields.io/badge/CodeGen-87b800) ![img](https://img.shields.io/badge/Defense-87b800) ![img](https://img.shields.io/badge/RAG-87b800) ![img](https://img.shields.io/badge/Chinese-87b800) 

   - Venue (Continuous update): ![img](https://img.shields.io/badge/conference-f1b800) or ![img](https://img.shields.io/badge/blog-f1b800)

- :sunflower: Welcome to recommend resources to us via <a href="https://github.com/ThuCCSLab/lm-ssp/issues"> <img src="https://icons.iconarchive.com/icons/github/octicons/128/issue-opened-16-icon.png" width="15" height="15"></a> Issues with the following format (**please fill in this table**): 

| Title | Link  | Code |   Venue |  Classification |  Model | Comment | 
| ---- |---- |---- |---- |---- |----|----| 
| aa |  arxiv | github  | bb'23    |  A1. Jailbreak | LLM  | Agent | 

# News 

- [2023.01.20] :fire: We collect `3` related papers from [NDSS'24](https://www.ndss-symposium.org/ndss2024/accepted-papers/)!
- [2023.01.17] :fire: We collect `108` related papers from [ICLR'24](https://openreview.net/group?id=ICLR.cc/2024/Conference)!
- [2023.01.09] :fire: LM-SSP is released!

# Roadmap

<img src="figure/map.png" alt="image" width="1000" height="auto" class="center">

# Collections
- [Book](collection/book.md)
- [Competition](collection/competition.md)
- [Leaderboard](collection/leaderboard.md)
- [Toolkit](collection/toolkit.md)
- [Survey](collection/survey.md)
- Paper
  - A. Safety
    - [A1. Jailbreak](collection/paper/safety/jailbreak.md)
    - [A2. Alignment](collection/paper/safety/alignment.md)
    - [A3. Deepfake](collection/paper/safety/deepfake.md)
    - [A4. Ethics](collection/paper/safety/ethics.md)
    - [A5. Fairness](collection/paper/safety/fairness.md)
    - [A6. Hallucination](collection/paper/safety/hallucination.md)
    - [A7. Toxicity](collection/paper/safety/toxicity.md)
  - B. Security
    - [B1. Adversarial Examples](collection/paper/security/adversarial_examples.md)
    - [B2. Poisoning](collection/paper/security/poisoning.md)
    - [B3. System](collection/paper/security/system.md)
  - C. Privacy
    - [C1. Contamination](collection/paper/privacy/contamination.md)
    - [C2. Copyright](collection/paper/privacy/copyright.md)
    - [C3. Data Reconstruction](collection/paper/privacy/data_reconstruction.md)
    - [C4. Extraction](collection/paper/privacy/extraction.md)
    - [C5. Inference](collection/paper/privacy/inference.md)
    - [C6. Privacy-Preserving Computation](collection/paper/privacy/privacy-preserving_computation.md)
    - [C7. Unlearning](collection/paper/privacy/unlearning.md)

# Star History

[![Star History Chart](https://api.star-history.com/svg?repos=ThuCCSLab/lm-ssp&type=Date)](https://star-history.com/#ThuCCSLab/lm-ssp&Date)

# Acknowledgement

- Organizers: [Tianshuo Cong](https://tianshuocong.github.io/), [Xinlei He](https://xinleihe.github.io/), [Zhengyu Zhao](https://zhengyuzhao.github.io/), [Yugeng Liu](https://liu.ai/)

- This project is inspired by [LLM Security](https://llmsecurity.net/), [Awesome LLM Security](https://github.com/corca-ai/awesome-llm-security), [LLM Security & Privacy](https://github.com/chawins/llm-sp),             [UR2-LLMs](https://github.com/jxzhangjhu/Awesome-LLM-Uncertainty-Reliability-Robustness), [PLMpapers](https://github.com/thunlp/PLMpapers), [EvaluationPapers4ChatGPT](https://github.com/THU-KEG/EvaluationPapers4ChatGPT)

<p align="center"><img src="figure/logo-new.png" width="900" /></p>

