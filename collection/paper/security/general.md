# B0. General
- [2025/05] **[A Large-Scale Empirical Analysis of Custom GPTs' Vulnerabilities in the OpenAI Ecosystem](https://arxiv.org/abs/2505.08148)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/03] **[Breaking the Loop: Detecting and Mitigating Denial-of-Service Vulnerabilities in Large Language Models](https://arxiv.org/abs/2503.00416)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/02] **[RACONTEUR: A Knowledgeable, Insightful, and Portable LLM-Powered Shell Command Explainer](https://arxiv.org/abs/2409.02074)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![NDSS'25](https://img.shields.io/badge/NDSS'25-f1b800)
- [2025/02] **[Towards Robust and Secure Embodied AI: A Survey on Vulnerabilities and Attacks](https://arxiv.org/abs/2502.13175)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![EmbodiedAI](https://img.shields.io/badge/EmbodiedAI-87b800)
- [2025/02] **[SoK: Understanding Vulnerabilities in the Large Language Model Supply Chain](https://arxiv.org/abs/2502.12497)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/01] **[SafeRAG: Benchmarking Security in Retrieval-Augmented Generation of Large Language Model](https://arxiv.org/abs/2501.18636)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![RAG](https://img.shields.io/badge/RAG-87b800)
- [2025/01] **[Data-Free Model-Related Attacks: Unleashing the Potential of Generative AI ](https://arxiv.org/abs/2501.16671)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![USENIX_Secuirty'25](https://img.shields.io/badge/USENIX_Secuirty'25-f1b800)
- [2024/11] **[Large Language Model Supply Chain: Open Problems From the Security Perspective](https://arxiv.org/abs/2411.01604)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Agent Security Bench (ASB): Formalizing and Benchmarking Attacks and Defenses in LLM-based Agents](https://arxiv.org/abs/2410.02644)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/agiresearch/ASB) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Agent](https://img.shields.io/badge/Agent-87b800)
- [2024/07] **[Securing the Future of GenAI: Policy and Technology](https://arxiv.org/abs/2407.12999)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[On the (In)Security of LLM App Stores](https://arxiv.org/abs/2407.08422)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![App](https://img.shields.io/badge/App-87b800)
- [2024/06] **[Security of AI Agents](https://arxiv.org/abs/2406.08689)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Agent](https://img.shields.io/badge/Agent-87b800)
- [2024/06] **[NYU CTF Dataset: A Scalable Open-Source Benchmark Dataset for Evaluating LLMs in Offensive Security](https://arxiv.org/abs/2406.05590)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Benchmark](https://img.shields.io/badge/Benchmark-87b800)
- [2024/04] **[CyberSecEval 2: A Wide-Ranging Cybersecurity Evaluation Suite for Large Language Models](https://arxiv.org/abs/2404.13161)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![AI_at_Meta](https://img.shields.io/badge/AI_at_Meta-f1b800)
- [2023/11] **[Identifying and Mitigating Vulnerabilities in LLM-Integrated Applications](https://arxiv.org/abs/2311.16153)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![AsiaCCS'24_Poster](https://img.shields.io/badge/AsiaCCS'24_Poster-f1b800)
