

# C6. Privacy-Preserving Computation

-  [2024/02] **[LLM-based Privacy Data Augmentation Guided by Knowledge Distillation With a Distribution Tutor for Medical Text Classification](https://arxiv.org/abs/2402.16515)** ![img](https://img.shields.io/badge/LLM-589cf4)
-  [2023/10] **[Locally Differentially Private Document Generation Using Zero Shot Prompting](https://arxiv.org/abs/2310.16111)** ![img](https://img.shields.io/badge/LLM-589cf4) ![img](https://img.shields.io/badge/EMNLP'23_(Findings)-f1b800)
-  [2023/09] **[Differentially Private Synthetic Data via Foundation Model APIs 1: Images](https://openreview.net/forum?id=YEhQs8POIo)** ![img](https://img.shields.io/badge/Diffusion-a99cf4) ![img](https://img.shields.io/badge/ICLR'24-f1b800)
-  [2023/09] **[DP-OPT: Make Large Language Model Your Differentially-Private Prompt Engineer](https://openreview.net/forum?id=Ifz3IgsEPX)** ![img](https://img.shields.io/badge/LLM-589cf4) ![img](https://img.shields.io/badge/ICLR'24_(Spotlight)-f1b800)
-  [2023/09] **[Enhancing Small Medical Learners With Privacy-Preserving Contextual Prompting](https://openreview.net/forum?id=ztpy1gsUpT)** ![img](https://img.shields.io/badge/LLM-589cf4) ![img](https://img.shields.io/badge/ICLR'24-f1b800)
-  [2023/09] **[Improving LoRA in Privacy-Preserving Federated Learning](https://openreview.net/forum?id=NLPzL6HWNl)** ![img](https://img.shields.io/badge/LLM-589cf4) ![img](https://img.shields.io/badge/ICLR'24-f1b800)
-  [2023/09] **[Privacy-Preserving in-Context Learning for Large Language Models](https://openreview.net/forum?id=x4OPJ7lHVU)** ![img](https://img.shields.io/badge/LLM-589cf4) ![img](https://img.shields.io/badge/ICLR'24-f1b800)
-  [2023/09] **[Privacy-Preserving in-Context Learning With Differentially Private Few-Shot Generation](https://openreview.net/forum?id=oZtt0pRnOl)** ![img](https://img.shields.io/badge/LLM-589cf4) ![img](https://img.shields.io/badge/ICLR'24-f1b800)
-  [2023/09] **[Privately Aligning Language Models With Reinforcement Learning](https://openreview.net/forum?id=3d0OmYTNui)** ![img](https://img.shields.io/badge/LLM-589cf4) ![img](https://img.shields.io/badge/ICLR'24-f1b800)
-  [2023/09] **[DP-Forward: Fine-Tuning and Inference on Language Models With Differential Privacy in Forward Pass](https://arxiv.org/abs/2309.06746)** ![img](https://img.shields.io/badge/LLM-589cf4) ![img](https://img.shields.io/badge/Defense-87b800) ![img](https://img.shields.io/badge/CCS'23-f1b800)
-  [2023/08] **[SIGMA: Secure GPT Inference With Function Secret Sharing](https://eprint.iacr.org/2023/1269)** ![img](https://img.shields.io/badge/LLM-589cf4)
-  [2023/07] **[CipherGPT: Secure Two-Party GPT Inference](https://eprint.iacr.org/2023/1147)** ![img](https://img.shields.io/badge/LLM-589cf4)
-  [2023/05] **[Privacy-Preserving Prompt Tuning for Large Language Model Services](https://arxiv.org/abs/2305.06212)** ![img](https://img.shields.io/badge/LLM-589cf4)
-  [2023/05] **[Privacy-Preserving Recommender Systems With Synthetic Query Generation Using Differentially Private Large Language Models](https://arxiv.org/abs/2305.05973)** ![img](https://img.shields.io/badge/LLM-589cf4)
-  [2022/10] **[EW-Tune: A Framework for Privately Fine-Tuning Large Language Models With Differential Privacy](https://arxiv.org/abs/2210.15042)** ![img](https://img.shields.io/badge/LLM-589cf4) ![img](https://img.shields.io/badge/ICDM'22_(Workshops)-f1b800)