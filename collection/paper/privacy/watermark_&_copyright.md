# C10. Watermark & Copyright
- [2025/10] **[Position: LLM Watermarking Should Align Stakeholders' Incentives for Practical Adoption](https://arxiv.org/abs/2510.18333)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/10] **[Learning to Watermark: A Selective Watermarking Framework for Large Language Models via Multi-Objective Optimization](https://arxiv.org/abs/2510.15976)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/10] **[EditMark: Watermarking Large Language Models based on Model Editing ](https://arxiv.org/abs/2510.16367)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/10] **[DistilLock: Safeguarding LLMs from Unauthorized Knowledge Distillation on the Edge](https://arxiv.org/abs/2510.16716)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/10] **[SynthID-Image: Image watermarking at internet scale](https://arxiv.org/abs/2510.09263)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/10] **[DITTO: A Spoofing Attack Framework on Watermarked LLMs via Knowledge Distillation](https://arxiv.org/abs/2510.10987)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/10] **[NoisePrints: Distortion-Free Watermarks for Authorship in Private Diffusion Models](https://arxiv.org/abs/2510.13793)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/10] **[SimKey: A Semantically Aware Key Module for Watermarking Language Models](https://arxiv.org/abs/2510.12828)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/10] **[Every Language Model Has a Forgery-Resistant Signature](https://arxiv.org/abs/2510.14086)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/10] **[Reading Between the Lines: Towards Reliable Black-box LLM Fingerprinting via Zeroth-order Gradient Estimation](https://arxiv.org/abs/2510.06605)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/10] **[CATMark: A Context-Aware Thresholding Framework for Robust Cross-Task Watermarking in Large Language Models](https://arxiv.org/abs/2510.02342)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/10] **[Secure and Robust Watermarking for AI-generated Images: A Comprehensive Survey](https://arxiv.org/abs/2510.02384)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/10] **[DMark: Order-Agnostic Watermarking for Diffusion Large Language Models](https://arxiv.org/abs/2510.02902)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/10] **[Fast, Secure, and High-Capacity Image Watermarking with Autoencoded Text Vectors](https://arxiv.org/abs/2510.00799)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/10] **[ZK-WAGON: Imperceptible Watermark for Image Generation Models using ZK-SNARKs](https://arxiv.org/abs/2510.01967)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/09] **[Watermarking Diffusion Language Models ](https://arxiv.org/abs/2509.24368)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/09] **[LLM Watermark Evasion via Bias Inversion](https://arxiv.org/abs/2509.23019)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/09] **[An Ensemble Framework for Unbiased Language Model Watermarking](https://arxiv.org/abs/2509.24043)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/09] **[Analyzing and Evaluating Unbiased Language Model Watermark](https://arxiv.org/abs/2509.24048)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/09] **[PRIVMARK: Private Large Language Models Watermarking with MPC](https://arxiv.org/abs/2509.24624)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/09] **[Fingerprinting LLMs via Prompt Injection](https://arxiv.org/abs/2509.25448)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/09] **[SeedPrints: Fingerprints Can Even Tell Which Seed Your Large Language Model Was Trained From](https://arxiv.org/abs/2509.26404)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/09] **[Are Robust LLM Fingerprints Adversarially Robust?](https://arxiv.org/abs/2509.26598)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/09] **[Guidance Watermarking for Diffusion Models](https://arxiv.org/abs/2509.22126)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/09] **[RLCracker: Exposing the Vulnerability of LLM Watermarks with Adaptive RL Attacks](https://arxiv.org/abs/2509.20924)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/09] **[PMark: Towards Robust and Distortion-free Semantic-level Watermarking with Channel Constraints](https://arxiv.org/abs/2509.21057)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/09] **[The Coding Limits of Robust Watermarking for Generative Models](https://arxiv.org/abs/2509.10577)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/09] **[A Content-dependent Watermark for Safeguarding Image Attribution](https://arxiv.org/abs/2509.10766)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/09] **[Removal Attack and Defense on AI-generated Content Latent-based Watermarking](https://arxiv.org/abs/2509.11745)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/09] **[Factuality Beyond Coherence: Evaluating LLM Watermarking Methods for Medical Texts](https://arxiv.org/abs/2509.07755)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/09] **[Character-Level Perturbations Disrupt LLM Watermarks](https://arxiv.org/abs/2509.09112)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/09] **[Dataset Ownership in the Era of Large Language Models](https://arxiv.org/abs/2509.05921)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/09] **[AMCR: A Framework for Assessing and Mitigating Copyright Risks in Generative Models ](https://arxiv.org/abs/2509.00641)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/09] **[PREE: Towards Harmless and Adaptive Fingerprint Editing in Large Language Models via Knowledge Prefix Enhancement](https://arxiv.org/abs/2509.00918)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/09] **[Clone What You Can't Steal: Black-Box LLM Replication via Logit Leakage and Distillation](https://arxiv.org/abs/2509.00973)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/09] **[EverTracer: Hunting Stolen Large Language Models via Stealthy and Robust Probabilistic Fingerprint ](https://arxiv.org/abs/2509.03058)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/09] **[PromptCOS: Towards System Prompt Copyright Auditing for LLMs via Content-level Output Similarity](https://arxiv.org/abs/2509.03117)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/08] **[OptMark: Robust Multi-bit Diffusion Watermarking via Inference Time Optimization](https://arxiv.org/abs/2508.21727)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/08] **[Robustness Assessment and Enhancement of Text Watermarking for Google's SynthID](https://arxiv.org/abs/2508.20228)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/08] **[SoK: Large Language Model Copyright Auditing via Fingerprinting](https://arxiv.org/abs/2508.19843)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/08] **[Copyright Protection for Large Language Models: A Survey of Methods, Challenges, and Trends](https://arxiv.org/abs/2508.11548)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/08] **[AuthPrint: Fingerprinting Generative Models Against Malicious Model Providers](https://arxiv.org/abs/2508.05691)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/PSMLab/authprint) ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/08] **[Anti-Tamper Protection for Unauthorized Individual Image Generation](https://arxiv.org/abs/2508.06325)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/Seeyn/Anti-Tamper-Perturbation) ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![ICCV'25](https://img.shields.io/badge/ICCV'25-f1b800)
- [2025/08] **[EditMF: Drawing an Invisible Fingerprint for Your Large Language Models](https://arxiv.org/abs/2508.08836)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/08] **[Attacks and Defenses Against LLM Fingerprinting](https://arxiv.org/abs/2508.09021)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/08] **[Majority Bit-Aware Watermarking For Large Language Models](https://arxiv.org/abs/2508.03829)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/08] **[RouteMark: A Fingerprint for Intellectual Property Attribution in Routing-based Model Merging](https://arxiv.org/abs/2508.01784)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/08] **[FPEdit: Robust LLM Fingerprinting through Localized Knowledge Editing](https://arxiv.org/abs/2508.02092)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/07] **[MaXsive: High-Capacity and Robust Training-Free Generative Image Watermarking in Diffusion Models ](https://arxiv.org/abs/2507.21195)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/07] **[Intrinsic Fingerprint of LLMs: Continue Training is NOT All You Need to Steal A Model!](https://arxiv.org/abs/2507.03014)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/07] **[When There Is No Decoder: Removing Watermarks from Stable Diffusion Models in a No-box Setting](https://arxiv.org/abs/2507.03646)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/07] **[Disappearing Ink: Obfuscation Breaks N-gram Code Watermarks in Theory and Practice](https://arxiv.org/abs/2507.05512)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/07] **[Enhancing LLM Watermark Resilience Against Both Scrubbing and Spoofing Attacks](https://arxiv.org/abs/2507.06274)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/07] **[Mitigating Watermark Stealing Attacks in Generative Models via Multi-Key Watermarking](https://arxiv.org/abs/2507.07871)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/07] **[Invariant-based Robust Weights Watermark for Large Language Models](https://arxiv.org/abs/2507.08288)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/06] **[Multi-use LLM Watermarking and the False Detection Problem](https://arxiv.org/abs/2506.15975)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/06] **[A Nested Watermark for Large Language Models](https://arxiv.org/abs/2506.17308)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/06] **[Blameless Users in a Clean Room: Defining Copyright Protection for Generative Models](https://arxiv.org/abs/2506.19881)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/06] **[CodeGuard: A Generalized and Stealthy Backdoor Watermarking for Generative Code Models](https://arxiv.org/abs/2506.20926)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/06] **[GaussMarker: Robust Dual-Domain Watermark for Diffusion Models](https://arxiv.org/abs/2506.11444)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/06] **[MEraser: An Effective Fingerprint Erasure Approach for Large Language Models](https://arxiv.org/abs/2506.12551)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/06] **[Watermarking LLM-Generated Datasets in Downstream Tasks](https://arxiv.org/abs/2506.13494)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/06] **[LexiMark: Robust Watermarking via Lexical Substitutions to Enhance Membership Verification of an LLM's Textual Training Data](https://arxiv.org/abs/2506.14474)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/06] **[Optimization-Free Universal Watermark Forgery with Regenerative Diffusion Models](https://arxiv.org/abs/2506.06018)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/06] **[StealthInk: A Multi-bit and Stealthy Watermark for Large Language Models](https://arxiv.org/abs/2506.05502)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/06] **[SoK: Are Watermarks in LLMs Ready for Deployment?](https://arxiv.org/abs/2506.05594)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/06] **[HeavyWater and SimplexWater: Watermarking Low-Entropy Text Distributions](https://arxiv.org/abs/2506.06409)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/06] **[Enhancing Watermarking Quality for LLMs via Contextual Generation States Awareness](https://arxiv.org/abs/2506.07403)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/06] **[Safeguarding Multimodal Knowledge Copyright in the RAG-as-a-Service Environment](https://arxiv.org/abs/2506.10030)** ![VLM](https://img.shields.io/badge/VLM-c7688b) ![RAG](https://img.shields.io/badge/RAG-87b800)
- [2025/06] **[A Crack in the Bark: Leveraging Public Knowledge to Remove Tree-Ring Watermarks](https://arxiv.org/abs/2506.10502)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![USENIX_Security'25](https://img.shields.io/badge/USENIX_Security'25-f1b800)
- [2025/06] **[ME: Trigger Element Combination Backdoor Attack on Copyright Infringement](https://arxiv.org/abs/2506.10776)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/06] **[Video Signature: In-generation Watermarking for Latent Video Diffusion Models](https://arxiv.org/abs/2506.00652)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![Video](https://img.shields.io/badge/Video-87b800)
- [2025/06] **[Watermarking Degrades Alignment in Language Models: Analysis and Mitigation](https://arxiv.org/abs/2506.04462)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[Watermarking Without Standards Is Not AI Governance](https://arxiv.org/abs/2505.23814)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[VideoMarkBench: Benchmarking Robustness of Video Watermarking](https://arxiv.org/abs/2505.21620)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/05] **[DuFFin: A Dual-Level Fingerprinting Framework for LLMs IP Protection](https://arxiv.org/abs/2505.16530)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[Robust LLM Fingerprinting via Domain-Specific Watermarks](https://arxiv.org/abs/2505.16723)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[CoTSRF: Utilize Chain of Thought as Stealthy and Robust Fingerprint of Large Language Models](https://arxiv.org/abs/2505.16785)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[Invisible Entropy: Towards Safe and Efficient Low-Entropy LLM Watermarking](https://arxiv.org/abs/2505.14112)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[MorphMark: Flexible Adaptive Watermarking for Large Language Models](https://arxiv.org/abs/2505.11541)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[Optimized Couplings for Watermarking Large Language Models](https://arxiv.org/abs/2505.08878)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ISIT'25](https://img.shields.io/badge/ISIT'25-f1b800)
- [2025/05] **[From Trade-off to Synergy: A Versatile Symbiotic Watermarking Framework for Large Language Models ](https://arxiv.org/abs/2505.09924)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ACL'25](https://img.shields.io/badge/ACL'25-f1b800)
- [2025/05] **[Revealing Weaknesses in Text Watermarking Through Self-Information Rewrite Attacks](https://arxiv.org/abs/2505.05190)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[LLM-Text Watermarking based on Lagrange Interpolation](https://arxiv.org/abs/2505.05712)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[RAP-SM: Robust Adversarial Prompt via Shadow Models for Copyright Verification of Large Language Models](https://arxiv.org/abs/2505.06304)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[Removing Watermarks with Partial Regeneration using Semantic Information ](https://arxiv.org/abs/2505.08234)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/05] **[Towards Dataset Copyright Evasion Attack against Personalized Text-to-Image Diffusion Models](https://arxiv.org/abs/2505.02824)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/05] **[LLM Watermarking Using Mixtures and Statistical-to-Computational Gaps](https://arxiv.org/abs/2505.01484)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[An End-to-End Model For Logits Based Large Language Models Watermarking](https://arxiv.org/abs/2505.02344)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[VIDSTAMP: A Temporally-Aware Watermark for Ownership and Integrity in Video Diffusion Models](https://arxiv.org/abs/2505.01406)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![Video](https://img.shields.io/badge/Video-87b800)
- [2025/04] **[Forging and Removing Latent-Noise Diffusion Watermarks Using a Single Image](https://arxiv.org/abs/2504.20111)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/04] **[GenPTW: In-Generation Image Watermarking for Provenance Tracing and Tamper Localization](https://arxiv.org/abs/2504.19567)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/04] **[VideoMark: A Distortion-Free Robust Watermarking Framework for Video Diffusion Models](https://arxiv.org/abs/2504.16359)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![Video](https://img.shields.io/badge/Video-87b800)
- [2025/04] **[What Lurks Within? Concept Auditing for Shared Diffusion Models at Scale](https://arxiv.org/abs/2504.14815)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/04] **[Gaussian Shading++: Rethinking the Realistic Deployment Challenge of Performance-Lossless Image Watermark for Diffusion Models](https://arxiv.org/abs/2504.15026)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/04] **[Protecting Your Voice: Temporal-aware Robust Watermarking](https://arxiv.org/abs/2504.14832)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![Speech](https://img.shields.io/badge/Speech-87b800)
- [2025/04] **[SOLIDO: A Robust Watermarking Method for Speech Synthesis via Low-Rank Adaptation](https://arxiv.org/abs/2504.15035)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![Speech](https://img.shields.io/badge/Speech-87b800)
- [2025/04] **[ArtistAuditor: Auditing Artist Style Pirate in Text-to-Image Generation Models](https://arxiv.org/abs/2504.13061)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![WWW'25](https://img.shields.io/badge/WWW'25-f1b800)
- [2025/04] **[PCDiff: Proactive Control for Ownership Protection in Diffusion Models with Watermark Compatibility ](https://arxiv.org/abs/2504.11774)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/04] **[PT-Mark: Invisible Watermarking for Text-to-image Diffusion Models via Semantic-aware Pivotal Tuning](https://arxiv.org/abs/2504.10853)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/04] **[Defending LLM Watermarking Against Spoofing Attacks with Contrastive Representation Learning](https://arxiv.org/abs/2504.06575)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/04] **[Detection Limits and Statistical Separability of Tree Ring Watermarks in Rectified Flow-based Text-to-Image Generation Models](https://arxiv.org/abs/2504.03850)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/04] **[Watermarking for AI Content Detection: A Review on Text, Visual, and Audio Modalities](https://arxiv.org/abs/2504.03765)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/04] **[How does Watermarking Affect Visual Language Models in Document Understanding?](https://arxiv.org/abs/2504.01048)** ![VLM](https://img.shields.io/badge/VLM-c7688b)
- [2025/03] **[Protecting Your Video Content: Disrupting Automated Video-based LLM Annotations](https://arxiv.org/abs/2503.21824)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![video](https://img.shields.io/badge/video-87b800) ![CVPR'25](https://img.shields.io/badge/CVPR'25-f1b800)
- [2025/03] **[Imperceptible but Forgeable: Practical Invisible Watermark Forgery via Diffusion Models](https://arxiv.org/abs/2503.22330)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/03] **[CEFW: A Comprehensive Evaluation Framework for Watermark in Large Language Models](https://arxiv.org/abs/2503.20802)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/03] **[SEAL: Semantic Aware Image Watermarking ](https://arxiv.org/abs/2503.12172)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/03] **[Towards A Correct Usage of Cryptography in Semantic Watermarks for Diffusion Models](https://arxiv.org/abs/2503.11404)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![_WMark@ICLR‘25](https://img.shields.io/badge/_WMark@ICLR‘25-f1b800)
- [2025/03] **[Mark Your LLM: Detecting the Misuse of Open-Source Large Language Models via Watermarking](https://arxiv.org/abs/2503.04636)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/03] **[Robust Data Watermarking in Language Models by Injecting Fictitious Knowledge](https://arxiv.org/abs/2503.04036)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/03] **[The Challenge of Identifying the Origin of Black-Box Large Language Models](https://arxiv.org/abs/2503.04332)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/02] **[Tracking the Copyright of Large Vision-Language Models through Parameter Learning Adversarial Images](https://arxiv.org/abs/2502.16593)** ![VLM](https://img.shields.io/badge/VLM-c7688b) ![ICLR'25](https://img.shields.io/badge/ICLR'25-f1b800)
- [2025/02] **[Merger-as-a-Stealer: Stealing Targeted PII from Aligned LLMs with Model Merging](https://arxiv.org/abs/2502.16094)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/02] **[Marking Code Without Breaking It: Code Watermarking for Detecting LLM-Generated Code](https://arxiv.org/abs/2502.18851)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/02] **[Obliviate: Efficient Unmemorization for Protecting Intellectual Property in Large Language Models](https://arxiv.org/abs/2502.15010)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/02] **[Secure and Efficient Watermarking for Latent Diffusion Models in Model Distribution Scenarios](https://arxiv.org/abs/2502.13345)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/02] **[Image Watermarks are Removable Using Controllable Regeneration from Clean Noise](https://arxiv.org/abs/2410.05470)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![ICLR'25](https://img.shields.io/badge/ICLR'25-f1b800)
- [2025/02] **[SWA-LDM: Toward Stealthy Watermarks for Latent Diffusion Models](https://arxiv.org/abs/2502.10495)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/02] **[Towards Watermarking of Open-Source LLMs](https://arxiv.org/abs/2502.10525)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/02] **[Dataset Protection via Watermarked Canaries in Retrieval-Augmented LLMs](https://arxiv.org/abs/2502.10673)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![RAG](https://img.shields.io/badge/RAG-87b800)
- [2025/02] **[Scalable Fingerprinting of Large Language Models](https://arxiv.org/abs/2502.07760)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/02] **[DERMARK: A Dynamic, Efficient and Robust Multi-bit Watermark for Large Language Models](https://arxiv.org/abs/2502.05213)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/02] **[SimMark: A Robust Sentence-Level Similarity-Based Watermarking Algorithm for Large Language Models](https://arxiv.org/abs/2502.02787)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/02] **[Robust and Secure Code Watermarking for Large Language Models via ML/Crypto Codesign](https://arxiv.org/abs/2502.02068)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/02] **[Model Provenance Testing for Large Language Models](https://arxiv.org/abs/2502.00706)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/01] **[PSyDUCK: Training-Free Steganography for Latent Diffusion ](https://arxiv.org/abs/2501.19172)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/01] **[LoRAGuard: An Effective Black-box Watermarking Approach for LoRAs](https://arxiv.org/abs/2501.15478)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/01] **[GaussMark: A Practical Approach for Structural Watermarking of Language Models](https://arxiv.org/abs/2501.13941)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/01] **[SEAL: Entangled White-box Watermarks on Low-Rank Adaptation](https://arxiv.org/abs/2501.09284)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/01] **[RAG-WM: An Efficient Black-Box Watermarking Approach for Retrieval-Augmented Generation of Large Language Models](https://arxiv.org/abs/2501.05249)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![RAG](https://img.shields.io/badge/RAG-87b800)
- [2025/01] **[SAT-LDM: Provably Generalizable Image Watermarking for Latent Diffusion Models with Self-Augmented Training](https://arxiv.org/abs/2501.00463)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/12] **[ExpShield: Safeguarding Web Text from Unauthorized Crawling and Language Modeling Exploitation](https://arxiv.org/abs/2412.21123)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/12] **[Copyright-Protected Language Generation via Adaptive Model Fusion](https://arxiv.org/abs/2412.06619)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/12] **[Black-Box Forgery Attacks on Semantic Watermarks for Diffusion Models](https://arxiv.org/abs/2412.03283)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/11] **[Do LLMs Know to Respect Copyright Notice?](https://aclanthology.org/2024.emnlp-main.1147.pdf)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![EMNLP'24](https://img.shields.io/badge/EMNLP'24-f1b800)
- [2024/11] **[SoK: Watermarking for AI-Generated Content](https://arxiv.org/abs/2411.18479)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![SoK](https://img.shields.io/badge/SoK-87b800)
- [2024/11] **[CDI: Copyrighted Data Identification in Diffusion Models](https://arxiv.org/abs/2411.12858)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/11] **[CopyrightMeter: Revisiting Copyright Protection in Text-to-image Models](https://arxiv.org/abs/2411.13144)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/11] **[WaterPark: A Robustness Assessment of Language Model Watermarking](https://arxiv.org/abs/2411.13425)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/11] **[One Prompt to Verify Your Models: Black-Box Text-to-Image Models Verification via Non-Transferable Adversarial Attacks](https://arxiv.org/abs/2410.22725)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/11] **[Debiasing Watermarks for Large Language Models via Maximal Coupling](https://arxiv.org/abs/2411.11203)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/11] **[CLUE-MARK: Watermarking Diffusion Models using CLWE](https://arxiv.org/abs/2411.11434)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/11] **[SoK: On the Role and Future of AIGC Watermarking in the Era of Gen-AI](https://arxiv.org/abs/2411.11478)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/11] **[Conceptwm: A Diffusion Model Watermark for Concept Protection](https://arxiv.org/abs/2411.11688)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/11] **[LLM App Squatting and Cloning](https://arxiv.org/abs/2411.07518)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/11] **[InvisMark: Invisible and Robust Watermarking for AI-generated Image Provenance](https://arxiv.org/abs/2411.07795)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/11] **[Watermarking Language Models through Language Models](https://arxiv.org/abs/2411.05091)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/11] **[Revisiting the Robustness of Watermarking to Paraphrasing Attacks](https://arxiv.org/abs/2411.05277)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/11] **[ROBIN: Robust and Invisible Watermarks for Diffusion Models with Adversarial Optimization](https://arxiv.org/abs/2411.03862)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/10] **[Embedding Watermarks in Diffusion Process for Model Intellectual Property Protection](https://arxiv.org/abs/2410.22445)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/10] **[Shallow Diffuse: Robust and Invisible Watermarking through Low-Dimensional Subspaces in Diffusion Models](https://arxiv.org/abs/2410.21088)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/10] **[Inevitable Trade-off between Watermark Strength and Speculative Sampling Efficiency for Language Models](https://arxiv.org/abs/2410.20418)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Watermarking Large Language Models and the Generated Content: Opportunities and Challenges](https://arxiv.org/abs/2410.19096)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Robust Watermarking Using Generative Priors Against Image Editing: From Benchmarking to Advances](https://arxiv.org/abs/2410.18775)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/10] **[Provably Robust Watermarks for Open-Source Language Models](https://arxiv.org/abs/2410.18861)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[REEF: Representation Encoding Fingerprints for Large Language Models](https://arxiv.org/abs/2410.14273)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[CoreGuard: Safeguarding Foundational Capabilities of LLMs Against Model Stealing in Edge Deployment](https://arxiv.org/abs/2410.13903)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[NSmark: Null Space Based Black-box Watermarking Defense Framework for Pre-trained Language Models](https://arxiv.org/abs/2410.13907)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[UTF:Undertrained Tokens as Fingerprints A Novel Approach to LLM Identification](https://arxiv.org/abs/2410.12318)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[FreqMark: Frequency-Based Watermark for Sentence-Level Detection of LLM-Generated Text](https://arxiv.org/abs/2410.10876)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[MergePrint: Robust Fingerprinting against Merging Large Language Models](https://arxiv.org/abs/2410.08604)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[An undetectable watermark for generative image models ](https://arxiv.org/abs/2410.07369)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/10] **[WAPITI: A Watermark for Finetuned Open-Source LLMs](https://arxiv.org/abs/2410.06467)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Signal Watermark on Large Language Models](https://arxiv.org/abs/2410.06545)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Ward: Provable RAG Dataset Inference via LLM Watermarks](https://arxiv.org/abs/2410.03537)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![RAG](https://img.shields.io/badge/RAG-87b800)
- [2024/10] **[Universally Optimal Watermarking Schemes for LLMs: from Theory to Practice](https://arxiv.org/abs/2410.02890)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Can Watermarked LLMs be Identified by Users via Crafted Prompts?](https://arxiv.org/abs/2410.03168)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[A Watermark for Black-Box Language Models](https://arxiv.org/abs/2410.02099)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Optimizing Adaptive Attacks against Content Watermarks for Language Models](https://arxiv.org/abs/2410.02440)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Discovering Clues of Spoofed LM Watermarks](https://arxiv.org/abs/2410.02693)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/09] **[Dormant: Defending against Pose-driven Human Image Animation](https://arxiv.org/abs/2409.14424)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/Manu21JC/Dormant) ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/09] **[A Certified Robust Watermark For Large Language Models](https://arxiv.org/abs/2409.19708)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/09] **[Multi-Designated Detector Watermarking for Language Models](https://arxiv.org/abs/2409.17518)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/09] **[Measuring Copyright Risks of Large Language Model via Partial Information Probing](https://arxiv.org/abs/2409.13831)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/09] **[Towards Effective User Attribution for Latent Diffusion Models via Watermark-Informed Blending](https://arxiv.org/abs/2409.10958)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/09] **[PersonaMark: Personalized LLM watermarking for model protection and user attribution](https://arxiv.org/abs/2409.09739)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/09] **[FP-VEC: Fingerprinting Large Language Models via Efficient Vector Addition](https://arxiv.org/abs/2409.08846)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/08] **[Watermarking Techniques for Large Language Models: A Survey](https://arxiv.org/abs/2409.00089)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Survey](https://img.shields.io/badge/Survey-87b800)
- [2024/08] **[MCGMark: An Encodable and Robust Online Watermark for LLM-Generated Malicious Code](https://arxiv.org/abs/2408.01354)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![codeGen](https://img.shields.io/badge/codeGen-87b800)
- [2024/08] **[Robustness of Watermarking on Text-to-Image Diffusion Models ](https://arxiv.org/abs/2408.02035)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/08] **[Hide and Seek: Fingerprinting Large Language Models with Evolutionary Learning](https://arxiv.org/abs/2408.02871)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[Strong Copyright Protection for Language Models via Adaptive Model Fusion](https://arxiv.org/abs/2407.20105)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[LLMmap: Fingerprinting For Large Language Models](https://arxiv.org/abs/2407.15847)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[SLIP: Securing LLMs IP Using Weights Decomposition](https://arxiv.org/abs/2407.10886)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[Hey, That's My Model! Introducing Chain & Hash, An LLM Fingerprinting Technique](https://arxiv.org/abs/2407.10887)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[Building Intelligence Identification System via Large Language Model Watermarking: A Survey and Beyond](https://arxiv.org/abs/2407.11100)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[Less is More: Sparse Watermarking in LLMs with Enhanced Text Quality](https://arxiv.org/abs/2407.13803)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[On Evaluating The Performance of Watermarked Machine-Generated Texts Under Adversarial Attacks](https://arxiv.org/abs/2407.04794)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[Waterfall: Framework for Robust and Scalable Text Watermarking](https://arxiv.org/abs/2407.04411)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[A Fingerprint for Large Language Models](https://arxiv.org/abs/2407.01235)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/06] **[AIGC-Chain: A Blockchain-Enabled Full Lifecycle Recording System for AIGC Product Copyright Management](https://arxiv.org/abs/2406.14966)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![Blockchain](https://img.shields.io/badge/Blockchain-87b800)
- [2024/06] **[PID: Prompt-Independent Data Protection Against Latent Diffusion Models](https://arxiv.org/abs/2406.15305)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![ICML'24](https://img.shields.io/badge/ICML'24-f1b800)
- [2024/06] **[PostMark: A Robust Blackbox Watermark for Large Language Models](https://arxiv.org/abs/2406.14517)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/06] **[EnTruth: Enhancing the Traceability of Unauthorized Dataset Usage in Text-to-image Diffusion Models with Minimal and Robust Alterations](https://arxiv.org/abs/2406.13933)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/06] **[Adversarial Perturbations Cannot Reliably Protect Artists From Generative AI](https://arxiv.org/abs/2406.12027)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/06] **[Hiding Text in Large Language Models: Introducing Unconditional Token Forcing Confusion](https://arxiv.org/abs/2406.02481)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/06] **[Bileve: Securing Text Provenance in Large Language Models Against Spoofing with Bi-level Signature](https://arxiv.org/abs/2406.01946)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/06] **[Edit Distance Robust Watermarks for Language Models](https://arxiv.org/abs/2406.02633)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[Black-Box Detection of Language Model Watermarks](https://arxiv.org/abs/2405.20777)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[Large Language Model Watermark Stealing With Mixed Integer Programming](https://arxiv.org/abs/2405.19677)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[FreezeAsGuard: Mitigating Illegal Adaptation of Diffusion Models via Selective Tensor Freezing](https://arxiv.org/abs/2405.17472)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/05] **[A Watermark for Low-entropy and Unbiased Generation in Large Language Models](https://arxiv.org/abs/2405.14604)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[Enhancing Watermarked Language Models to Identify Users](https://arxiv.org/abs/2405.11109)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[AquaLoRA: Toward White-box Protection for Customized Stable Diffusion Models via Watermark LoRA](https://arxiv.org/abs/2405.11135)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/05] **[Stylometric Watermarks for Large Language Models](https://arxiv.org/abs/2405.08400)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[UnMarker: A Universal Attack on Defensive Watermarking](https://arxiv.org/abs/2405.08363)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/05] **[Stable Signature is Unstable: Removing Image Watermark from Diffusion Models](https://arxiv.org/abs/2405.07145)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/05] **[Adaptive and robust watermark against model extraction attack](https://arxiv.org/abs/2405.02365)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[ProFLingo: A Fingerprinting-based Copyright Protection Scheme for Large Language Models](https://arxiv.org/abs/2405.02466)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[DiffuseTrace: A Transparent and Flexible Watermarking Scheme for Latent Diffusion Model](https://arxiv.org/abs/2405.02696)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/05] **[Lazy Layers to Make Fine-Tuned Diffusion Models More Traceable](https://arxiv.org/abs/2405.00466)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/04] **[Disguised Copyright Infringement of Latent Diffusion Model](https://arxiv.org/abs/2404.06737)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/04] **[Gaussian Shading: Provable Performance-Lossless Image Watermarking for Diffusion Models](https://arxiv.org/abs/2404.04956)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![CVPR'24](https://img.shields.io/badge/CVPR'24-f1b800)
- [2024/04] **[Have You Merged My Model? On The Robustness of Large Language Model IP Protection Methods Against Model Merging](https://arxiv.org/abs/2404.05188)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![LAMPS@CCS‘24](https://img.shields.io/badge/LAMPS@CCS‘24-f1b800) ![Best Paper](https://img.shields.io/badge/Best_paper-ff0000)
- [2024/04] **[A Training-Free Plug-and-Play Watermark Framework for Stable Diffusion](https://arxiv.org/abs/2404.05607)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/04] **[Topic-based Watermarks for LLM-Generated Text](https://arxiv.org/abs/2404.02138)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/04] **[A Statistical Framework of Watermarks for Large Language Models: Pivot, Detection Efficiency and Optimal Rules](https://arxiv.org/abs/2404.01245)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[RAW: A Robust and Agile Plug-and-Play Watermark Framework for AI-Generated Images with Provable Guarantees](https://arxiv.org/abs/2403.18774)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/03] **[Is Watermarking LLM-Generated Code Robust?](https://arxiv.org/abs/2403.17983)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![codeGen](https://img.shields.io/badge/codeGen-87b800)
- [2024/03] **[Ghost Sentence: A Tool for Everyday Users to Copyright Data from Large Language Models](https://arxiv.org/abs/2403.15740)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[Bypassing LLM Watermarks with Color-Aware Substitutions](https://arxiv.org/abs/2403.14719)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[A Transfer Attack to Image Watermarks](https://arxiv.org/abs/2403.15365)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/03] **[An Entropy-based Text Watermarking Detection Method](https://arxiv.org/abs/2403.13485)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[Duwak: Dual Watermarks in Large Language Models](https://arxiv.org/abs/2403.13000)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[Towards Better Statistical Understanding of Watermarking LLMs](https://arxiv.org/abs/2403.13027)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[Learning to Watermark LLM-generated Text via Reinforcement Learning](https://arxiv.org/abs/2403.10553)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[A Watermark-Conditioned Diffusion Model for IP Protection](https://arxiv.org/abs/2403.10893)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/03] **[Hufu: A Modality-Agnositc Watermarking System for Pre-Trained Transformers via Permutation Equivariance](https://arxiv.org/abs/2403.05842)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[WaterMax: breaking the LLM watermark detectability-robustness-quality trade-off](https://arxiv.org/abs/2403.04808)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[Watermark Stealing in Large Language Models](https://arxiv.org/abs/2402.19361)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[Token-Specific Watermarking with Enhanced Detectability and Semantic Coherence for Large Language Models](https://arxiv.org/abs/2402.18059)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[EmMark: Robust Watermarks for IP Protection of Embedded Quantized Large Language Models](https://arxiv.org/abs/2402.17938)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[Generative Models are Self-Watermarked: Declaring Model Authentication through Re-Generation](https://arxiv.org/abs/2402.16889)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/02] **[Attacking LLM Watermarks by Exploiting Their Strengths](https://arxiv.org/abs/2402.16187)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[Double-I Watermark: Protecting Model Copyright for LLM Fine-tuning](https://arxiv.org/abs/2402.14883)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800)
- [2024/02] **[Watermarking Makes Language Models Radioactive](https://arxiv.org/abs/2402.14904)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800)
- [2024/02] **[Can Watermarks Survive Translation? On the Cross-lingual Consistency of Text Watermark for Large Language Models](https://arxiv.org/abs/2402.14007)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[A Survey of Text Watermarking in the Era of Large Language Models](https://arxiv.org/abs/2312.07913)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Survey](https://img.shields.io/badge/Survey-87b800)
- [2024/02] **[Proving membership in LLM pretraining data via data watermarks](https://arxiv.org/abs/2402.10892)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800)
- [2024/02] **[Resilient Watermarking for LLM-Generated Codes](https://arxiv.org/abs/2402.07518)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800)
- [2024/02] **[Permute-and-Flip: An optimally robust and watermarkable decoder for LLMs](https://arxiv.org/abs/2402.05864)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/XuandongZhao/pf-decoding) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800)
- [2024/02] **[Copyright Protection in Generative AI: A Technical Perspective ](https://arxiv.org/abs/2402.02333)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/01] **[Adaptive Text Watermark for Large Language Models](https://arxiv.org/abs/2401.13927)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/01] **[Instructional Fingerprinting of Large Language Models](https://arxiv.org/abs/2401.12255)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/01] **[Generative AI Has a Visual Plagiarism Problem](https://spectrum.ieee.org/midjourney-copyright)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![Blog](https://img.shields.io/badge/Blog-f1b800)
- [2023/12] **[HuRef: HUman-REadable Fingerprint for Large Language Models](https://arxiv.org/abs/2312.04828)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![NeurIPS'24](https://img.shields.io/badge/NeurIPS'24-f1b800)
- [2023/12] **[Human-Readable Fingerprint for Large Language Models](https://arxiv.org/abs/2312.04828)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/12] **[Mark My Words: Analyzing and Evaluating Language Model Watermarks](https://arxiv.org/abs/2312.00273)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/wagner-group/MarkMyWords) ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/11] **[WatME: Towards Lossless Watermarking Through Lexical Redundancy ](https://arxiv.org/abs/2311.09832)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ACL'24](https://img.shields.io/badge/ACL'24-f1b800)
- [2023/11] **[WaterBench: Towards Holistic Evaluation of Watermarks for Large Language Models](https://arxiv.org/abs/2311.07138)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/THU-KEG/WaterBench) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ACL'24](https://img.shields.io/badge/ACL'24-f1b800)
- [2023/11] **[Towards More Effective Protection Against Diffusion-Based Mimicry with Score Distillation](https://arxiv.org/abs/2311.12832)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/xavihart/Diff-Protect) ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/11] **[A Robust Semantics-based Watermark for Large Language Model against Paraphrasing](https://arxiv.org/abs/2311.08721)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/11] **[Protecting Intellectual Property of Large Language Model-Based Code Generation APIs via Watermarks](https://dl.acm.org/doi/abs/10.1145/3576915.3623120)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![CodeGen](https://img.shields.io/badge/CodeGen-87b800) ![CCS'23](https://img.shields.io/badge/CCS'23-f1b800)
- [2023/10] **[REMARK-LLM: A Robust and Efficient Watermarking Framework for Generative Large Language Models ](https://arxiv.org/abs/2310.12362)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![USENIX_Security'24](https://img.shields.io/badge/USENIX_Security'24-f1b800)
- [2023/10] **[Watermarking LLMs with Weight Quantization](https://arxiv.org/abs/2310.11237)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![EMNLP‘23_(Findings)](https://img.shields.io/badge/EMNLP‘23_(Findings)-f1b800)
- [2023/09] **[A Private Watermark for Large Language Models](https://openreview.net/forum?id=gMLQwKDY3N)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[A Semantic Invariant Robust Watermark for Large Language Models](https://openreview.net/forum?id=6p8lpe4MNf)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[Provable Robust Watermarking for AI-Generated Text](https://openreview.net/forum?id=SsmT8aO45L)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore](https://openreview.net/forum?id=ruk0nyQPec)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24_(Spotlight)](https://img.shields.io/badge/ICLR'24_(Spotlight)-f1b800)
- [2023/08] **[PromptCARE: Prompt Copyright Protection by Watermark Injection and Verification](https://arxiv.org/abs/2308.02816)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/grasses/PromptCARE) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![S&P'24](https://img.shields.io/badge/S&P'24-f1b800)
- [2023/06] **[Generative Watermarking Against Unauthorized Subject-Driven Image Synthesis](https://arxiv.org/abs/2306.07754)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2023/05] **[Tree-Ring Watermarks: Fingerprints for Diffusion Images that are Invisible and Robust](https://arxiv.org/abs/2305.20030)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/YuxinWenRick/tree-ring-watermark) ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![NeurIPS'23](https://img.shields.io/badge/NeurIPS'23-f1b800)
- [2023/05] **[Watermarking Diffusion Model](https://arxiv.org/abs/2305.12502)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2023/03] **[A Recipe for Watermarking Diffusion Models](https://arxiv.org/abs/2303.10137)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/yunqing-me/WatermarkDM) ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2023/02] **[Glaze: Protecting Artists from Style Mimicry by Text-to-Image Models](https://arxiv.org/abs/2302.04222)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://glaze.cs.uchicago.edu/) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![USENIX_Security'23](https://img.shields.io/badge/USENIX_Security'23-f1b800) ![Best Paper](https://img.shields.io/badge/Best_paper-ff0000)
- [2023/01] **[A Watermark for Large Language Models](https://arxiv.org/abs/2301.10226)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](github.com/jwkirchenbauer/lm-watermarking) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICML'23](https://img.shields.io/badge/ICML'23-f1b800) ![Best Paper](https://img.shields.io/badge/Best_paper-ff0000)
