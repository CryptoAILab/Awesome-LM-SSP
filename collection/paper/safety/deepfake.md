

# A3. Deepfake

-  [2024/03] **[A Survey of AI-generated Text Forensic Systems: Detection, Attribution, and Characterization](https://arxiv.org/abs/2403.01152)** ![img](https://img.shields.io/badge/LLM-589cf4) ![img](https://img.shields.io/badge/Survey-87b800)
-  [2024/02] **[Technical Report on the Checkfor.ai AI-Generated Text Classifier](https://arxiv.org/abs/2402.14873)** <a href="https://checkfor.ai/"><img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" width="15" height="15"></a> ![img](https://img.shields.io/badge/LLM-589cf4)
-  [2024/02] **[VGMShield: Mitigating Misuse of Video Generative Models](https://arxiv.org/abs/2402.13126)** ![img](https://img.shields.io/badge/VLM-c7688b) ![img](https://img.shields.io/badge/Video-87b800)
-  [2024/02] **[M4gt-Bench: Evaluation Benchmark for Black-Box Machine-Generated Text Detection](https://arxiv.org/abs/2402.11175)** ![img](https://img.shields.io/badge/LLM-589cf4)
-  [2024/02] **[Ten Words Only Still Help: Improving Black-Box AI-Generated Text Detection via Proxy-Guided Efficient Re-Sampling](https://arxiv.org/abs/2402.09199)** ![img](https://img.shields.io/badge/LLM-589cf4)
-  [2024/02] **[Does DETECTGPT Fully Utilize Perturbation? Selective Perturbation on Model-Based Contrastive Learning Detector Would Be Better](https://arxiv.org/abs/2402.00263)** ![img](https://img.shields.io/badge/LLM-589cf4)
-  [2024/02] **[TELLER: A Trustworthy Framework for Explainable, Generalizable and Controllable Fake News Detection](https://arxiv.org/abs/2402.07776)** ![img](https://img.shields.io/badge/LLM-589cf4)
-  [2024/02] **[Organic or Diffused: Can We Distinguish Human Art From AI-generated Images?](https://arxiv.org/abs/2402.03214)** ![img](https://img.shields.io/badge/Diffusion-a99cf4)
-  [2024/01] **[Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated Text](https://arxiv.org/abs/2401.12070)** <a href="https://github.com/ahans30/Binoculars"><img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" width="15" height="15"></a> ![img](https://img.shields.io/badge/LLM-589cf4)
-  [2024/01] **[Enhancing Robustness of LLM-Synthetic Text Detectors for Academic Writing: A Comprehensive Analysis](https://arxiv.org/abs/2401.08046)** ![img](https://img.shields.io/badge/LLM-589cf4)
-  [2024/01] **[Authorship Obfuscation in Multilingual Machine-Generated Text Detection](https://arxiv.org/abs/2401.07867)** ![img](https://img.shields.io/badge/LLM-589cf4) ![img](https://img.shields.io/badge/Multilingual-87b800)
-  [2024/01] **[Few-Shot Detection of Machine-Generated Text Using Style Representations](https://arxiv.org/abs/2401.06712)** ![img](https://img.shields.io/badge/LLM-589cf4)
-  [2024/01] **[LLM-as-a-Coauthor: The Challenges of Detecting LLM-Human Mixcase](https://arxiv.org/abs/2401.05952)** <a href="https://github.com/Dongping-Chen/MixSet"><img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" width="15" height="15"></a> ![img](https://img.shields.io/badge/LLM-589cf4)
-  [2023/10] **[Harnessing the Power of ChatGPT in Fake News: An in-Depth Exploration in Generation, Detection and Explanation](https://arxiv.org/abs/2310.05046)** ![img](https://img.shields.io/badge/LLM-589cf4)
-  [2023/09] **[Can LLM-Generated Misinformation Be Detected?](https://openreview.net/forum?id=ccxD4mtkTU)** ![img](https://img.shields.io/badge/LLM-589cf4) ![img](https://img.shields.io/badge/ICLR'24-f1b800)
-  [2023/09] **[Detecting Machine-Generated Texts by Multi-Population Aware Optimization for Maximum Mean Discrepancy](https://openreview.net/forum?id=3fEKavFsnv)** ![img](https://img.shields.io/badge/LLM-589cf4) ![img](https://img.shields.io/badge/ICLR'24-f1b800)
-  [2023/09] **[Robustness of AI-Image Detectors: Fundamental Limits and Practical Attacks](https://openreview.net/forum?id=dLoAdIKENc)** ![img](https://img.shields.io/badge/Diffusion-a99cf4) ![img](https://img.shields.io/badge/ICLR'24-f1b800)
-  [2023/05] **[On the Risk of Misinformation Pollution With Large Language Models](https://arxiv.org/abs/2305.13661)** ![img](https://img.shields.io/badge/LLM-589cf4) ![img](https://img.shields.io/badge/EMNLP'23_(Findings)-f1b800)
-  [2023/05] **[Evading Watermark Based Detection of AI-Generated Content](https://arxiv.org/abs/2305.03807)** ![img](https://img.shields.io/badge/LLM-589cf4) ![img](https://img.shields.io/badge/CCS'23-f1b800)
-  [2023/04] **[Synthetic Lies: Understanding AI-Generated Misinformation and Evaluating Algorithmic and Human Solutions](https://doi.org/10.1145/3544548.3581318)** ![img](https://img.shields.io/badge/LLM-589cf4) ![img](https://img.shields.io/badge/CHI'23-f1b800)
-  [2023/03] **[Can AI-Generated Text Be Reliably Detected?](https://arxiv.org/abs/2303.11156)** ![img](https://img.shields.io/badge/LLM-589cf4)
-  [2023/03] **[MGTBench: Benchmarking Machine-Generated Text Detection](https://arxiv.org/abs/2303.14822)** <a href="https://github.com/xinleihe/MGTBench"><img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" width="15" height="15"></a> ![img](https://img.shields.io/badge/LLM-589cf4)
-  [2022/12] **[Discovering Language Model Behaviors With Model-Written Evaluations](https://arxiv.org/abs/2212.09251)** ![img](https://img.shields.io/badge/LLM-589cf4) ![img](https://img.shields.io/badge/ACL'23_(Findings)-f1b800)
-  [2022/12] **[CoCo: Coherence-Enhanced Machine-Generated Text Detection Under Data Limitation With Contrastive Learning](https://arxiv.org/abs/2212.10341)** ![img](https://img.shields.io/badge/LLM-589cf4)
-  [2022/10] **[DE-FAKE: Detection and Attribution of Fake Images Generated by Text-to-Image Generation Models](https://arxiv.org/abs/2210.06998)** ![img](https://img.shields.io/badge/Diffusion-a99cf4) ![img](https://img.shields.io/badge/CCS'23-f1b800)